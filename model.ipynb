import pandas as pd

df = pd.read_csv("transactions_train.csv")
display(df.head())
# Examine the shape of the data
print(f"Shape of the DataFrame: {df.shape}")

# Check data types
print("\nData types of columns:")
print(df.dtypes)

# Explore the distribution of key features using descriptive statistics
print("\nDescriptive statistics for key features:")
key_features = ["transaction_amount", "is_fraud"]
display(df[key_features].describe())
# Identify missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Calculate correlations between features, excluding non-numerical columns
print("\nCorrelation matrix (including 'is_fraud'):")
correlation_matrix = df.select_dtypes(include=['number']).corr() # Select only numerical columns
display(correlation_matrix["is_fraud"].sort_values(ascending=False))
# Remove non-numerical columns before calculating the correlation
numerical_df = df.select_dtypes(include=['number'])

# Calculate correlations between features
print("\nCorrelation matrix (including 'is_fraud'):")
correlation_matrix = numerical_df.corr()
display(correlation_matrix["is_fraud"].sort_values(ascending=False))
# Check for missing values
missing_values = df.isnull().sum()
print("Missing values in each column:\n", missing_values)

# Handle missing values (replace with mean for numerical features)
for column in df.columns:
  if df[column].dtype in ['int64', 'float64'] and df[column].isnull().any():
    df[column].fillna(df[column].mean(), inplace=True)

# Check if missing values are handled
missing_values_after_handling = df.isnull().sum()
print("\nMissing values after handling:\n", missing_values_after_handling)
import matplotlib.pyplot as plt

# Select numerical features
numerical_features = df.select_dtypes(include=['number'])

# Create box plots for numerical features
for column in numerical_features.columns:
  plt.figure(figsize=(8, 4))
  plt.boxplot(numerical_features[column])
  plt.title(f"Box plot of {column}")
  plt.show()

# Calculate the IQR for transaction_amount
Q1 = df['transaction_amount'].quantile(0.25)
Q3 = df['transaction_amount'].quantile(0.75)
IQR = Q3 - Q1

# Define upper and lower bounds for outliers
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

# Cap outliers
df['transaction_amount'] = df['transaction_amount'].clip(lower_bound, upper_bound)
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Identify categorical features
categorical_features = ['transaction_channel', 'transaction_payment_mode_anonymous', 'payment_gateway_bank_anonymous', 'payer_browser_anonymous', 'payer_email_anonymous', 'payee_ip_anonymous', 'payer_mobile_anonymous', 'transaction_id_anonymous', 'payee_id_anonymous']

# Encode categorical features using LabelEncoder
le = LabelEncoder()
for feature in categorical_features:
  if feature in df.columns:
    df[feature] = le.fit_transform(df[feature].astype(str))

# Identify numerical features
numerical_features = ['transaction_amount']

# Scale numerical features using StandardScaler
scaler = StandardScaler()
for feature in numerical_features:
  if feature in df.columns:
    df[feature] = scaler.fit_transform(df[[feature]])
from sklearn.model_selection import train_test_split

# Define features (X) and target variable (y)
X = df.drop('is_fraud', axis=1)
y = df['is_fraud']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier

# Define features (X) and target variable (y)
# Drop 'transaction_date' from the features
X = df.drop(['is_fraud', 'transaction_date'], axis=1)  
y = df['is_fraud']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

# Instantiate a DecisionTreeClassifier
dt_model = DecisionTreeClassifier()

# Fit the model to the training data (should work now)
dt_model.fit(X_train, y_train)
#X_train = X_train.drop('transaction_date', axis=1)
#X_test = X_test.drop('transaction_date', axis=1)

# Instantiate a DecisionTreeClassifier
dt_model = DecisionTreeClassifier()

# Fit the model to the training data
dt_model.fit(X_train, y_train)
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

# Make predictions on the test data
y_pred = dt_model.predict(X_test)

# Calculate evaluation metrics
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Print the evaluation metrics
print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1-score: {f1}")

# Generate confusion matrix
confusion_mat = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(confusion_mat)
from imblearn.over_sampling import SMOTE

# Instantiate SMOTE with a smaller value for k_neighbors
smote = SMOTE(random_state=42, k_neighbors=min(3, len(y_train[y_train == 1]) -1) ) # Adjust k_neighbors if needed


# Resample the training data
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Train the Decision Tree Classifier on the resampled data
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train_resampled, y_train_resampled)
from sklearn.ensemble import RandomForestClassifier

# Instantiate RandomForestClassifier with class weights
rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)

# Train the model on the original training data
rf_model.fit(X_train, y_train)
from xgboost import XGBClassifier

# Instantiate XGBClassifier
xgb_model = XGBClassifier(scale_pos_weight=len(y_train[y_train == 0]) / len(y_train[y_train == 1]), random_state=42)  

# Train the model on the original training data
xgb_model.fit(X_train, y_train)
import pandas as pd

df = pd.read_csv("transactions_train.csv")  # Replace with your CSV file name

total_fraud = df['is_fraud'].sum()
print(f"Total number of fraudulent transactions: {total_fraud}")
